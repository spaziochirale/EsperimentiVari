{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spaziochirale/EsperimentiVari/blob/main/rag_chatbot_pdf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prototipo di ChatBot RAG con LangChain e PDF\n",
        "\n",
        "Questo notebook mostra come realizzare un *chatBot* di tipo **RAG** utilizzando il framework **LangChain** e un file PDF come base di conoscenza."
      ],
      "metadata": {
        "id": "xSb_t-bqnMrf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Per prima cosa installiamo sul server alcuni package Python della piattaforma LangChain e altre librerie necessarie che utilizzeremo nel prototipo."
      ],
      "metadata": {
        "id": "81CAjqFnnh_b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X12-HGndcj5v"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain langchain_community langchain_chroma pypdf langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impostiamo la chiave API di OpenAI e creiamo l'oggetto `llm`."
      ],
      "metadata": {
        "id": "Y11z0LG1qfp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")"
      ],
      "metadata": {
        "id": "HaQjPajReTIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importiamo le librerie necessarie per il nostro progetto."
      ],
      "metadata": {
        "id": "oADDwAC3r7oH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "QdDVr0Acfk5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La cella che segue genera una lista di oggetti di tipo ***LangChain Document*** a partire dal file PDF specificato come percorso. Un Document LangChain ha come contenuto un testo in formato TXT.\n",
        "**PyPDFLoader** crea un documento per ogni pagina del file PDF.\n",
        "\n",
        "Le istruzioni commentate consentono di caricare il file attraverso l'utility Colab ***files.upload***, tuttavia è più veloce trascinare il file nell'area File System del Notebook attivo e poi copiare direttamente il percorso come argomento stringa alla PyPDFLoader."
      ],
      "metadata": {
        "id": "5nRULG7MvBlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "#pdf_file = list(uploaded.keys())[0]  # Prende il nome del primo file caricato\n",
        "\n",
        "# AGGIORNARE CON IL PATH EFFETTIVO AL FILE CARICATO\n",
        "loader = PyPDFLoader('/content/Z9RG_(It)05.pdf')\n",
        "docs = loader.load()\n",
        "print('Numero pagine caricate:',len(docs))"
      ],
      "metadata": {
        "id": "kyI-hIfIuxbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividiamo il contenuto del PDF in chunks e creiamo il database vettoriale. Per un documento PDF ben strutturato ogni pagina potrebbe corrispondere ad un chunk. Il parametro chunk_size è sovradimensionato rispetto alla lunghezza in caratteri della pagina di un tipico manuale utente PDF, per cui il numero di chunks dovrebbe essere pari al numero di pagine per la maggior parte dei documenti."
      ],
      "metadata": {
        "id": "wPHXvQtNvzDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=6000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "print('Numero chunks creati:',len(splits))\n",
        "\n",
        "# Creo il vectorstore utilizzando la versione con rappresentazione in memoria di Chroma (non viene creato un db su file)\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(model=\"text-embedding-3-large\"))"
      ],
      "metadata": {
        "id": "zDGR1ZCJvpTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creiamo il retriever e prepariamo il prompt template."
      ],
      "metadata": {
        "id": "seUQmPwQx0eF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "template = \"\"\"Sei un assistente che aiuta l'utente a trovare soluzioni alle procedure di uso del prodotto. Usa come contesto i contenuti recuperati dal manuale utente. Per la risposta usa anche le tue competenze generali, ma se il contesto non contiene elementi pertinenti consiglia di rivolgersi ad un assistente umano.\n",
        "\n",
        "Question: {question}\n",
        "Context: {context}\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"],\n",
        "    template=template\n",
        ")\n"
      ],
      "metadata": {
        "id": "u9cefv8qxl5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definiamo una funzione di utilità per formattare i documenti."
      ],
      "metadata": {
        "id": "qmFGhwqazquP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "SJh4SC4rzmJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definiamo la chain RAG."
      ],
      "metadata": {
        "id": "hbBkNx9wz_UJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "YKFylSs_z57q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ora possiamo utilizzare la chain RAG per porre domande sul contenuto del PDF."
      ],
      "metadata": {
        "id": "74J1v0x_2MWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Perché il monitor nel mirino è spento?\"\n",
        "rag_chain.invoke(question)"
      ],
      "metadata": {
        "id": "_gs_1L2rhuId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se vogliamo testare l'operazione di retrival, possiamo usare la cella seguente."
      ],
      "metadata": {
        "id": "khwH-siOO2IX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.invoke(\"Perché il monitor nel mirino è spento?\")"
      ],
      "metadata": {
        "id": "XOtGUAuYFUBa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}